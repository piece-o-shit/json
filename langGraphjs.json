[

{
"documentation":

[

{
"title": 
"Create Assistant"
,
"description": 
"Create an assistant. An initial version of the assistant will be created and the assistant is set to that version. To change versions, use the `POST /assistants/{assistant_id}/latest` endpoint."
,
"code_examples":

[
"```hljs curl curl https://langchain-ai.github.io/assistants \ --request POST \ --header 'Content-Type: application/json' \ --data '{ "assistant_id": "", "graph_id": "", "config": {}, "metadata": {}, "if_exists": "raise", "name": "" }' ```"
]
,
"api_references":

[

{
"method": 
"POST"
,
"endpoint": 
"/assistants"
,
"parameters":

[
"assistant_id"
,
"graph_id"
,
"config"
,
"metadata"
,
"if_exists"
,
"name"
]
}
]
}

,

{
"title": 
"Search Assistants"
,
"description": 
"Search for assistants. This endpoint also functions as the endpoint to list all assistants."
,
"code_examples":

[
"```hljs curl curl https://langchain-ai.github.io/assistants/search \ --request POST \ --header 'Content-Type: application/json' \ --data '{ "metadata": {}, "graph_id": "", "limit": 10, "offset": 0 }' ```"
]
,
"api_references":

[

{
"method": 
"POST"
,
"endpoint": 
"/assistants/search"
,
"parameters":

[
"metadata"
,
"graph_id"
,
"limit"
,
"offset"
]
}
]
}

,

{
"title": 
"Get Assistant"
,
"description": 
"Get an assistant by ID."
,
"code_examples":

[
"```hljs curl curl 'https://langchain-ai.github.io/assistants/{assistant_id}' ```"
]
,
"api_references":

[

{
"method": 
"GET"
,
"endpoint": 
"/assistants/{assistant_id}"
,
"parameters":

[
"assistant_id"
]
}
]
}

,

{
"title": 
"Delete Assistant"
,
"description": 
"Delete an assistant by ID. All versions of the assistant will be deleted as well."
,
"code_examples":

[
"```hljs curl curl 'https://langchain-ai.github.io/assistants/{assistant_id}' \ --request DELETE ```"
]
,
"api_references":

[

{
"method": 
"DELETE"
,
"endpoint": 
"/assistants/{assistant_id}"
,
"parameters":

[
"assistant_id"
]
}
]
}

,

{
"title": 
"Patch Assistant"
,
"description": 
"Update an assistant."
,
"code_examples":

[
"```hljs curl curl 'https://langchain-ai.github.io/assistants/{assistant_id}' \ --request PATCH \ --header 'Content-Type: application/json' \ --data '{ "graph_id": "", "config": {}, "metadata": {}, "name": "" }' ```"
]
,
"api_references":

[

{
"method": 
"PATCH"
,
"endpoint": 
"/assistants/{assistant_id}"
,
"parameters":

[
"assistant_id"
,
"graph_id"
,
"config"
,
"metadata"
,
"name"
]
}
]
}

,

{
"title": 
"Get Assistant Graph"
,
"description": 
"Get an assistant's graph by ID."
,
"code_examples":

[
"```hljs curl curl 'https://langchain-ai.github.io/assistants/{assistant_id}/graph' ```"
]
,
"api_references":

[

{
"method": 
"GET"
,
"endpoint": 
"/assistants/{assistant_id}/graph"
,
"parameters":

[
"assistant_id"
]
}
]
}

,

{
"title": 
"Get Assistant Subgraphs"
,
"description": 
"Get an assistant's subgraphs."
,
"code_examples":

[
"```hljs curl curl 'https://langchain-ai.github.io/assistants/{assistant_id}/subgraphs' ```"
]
,
"api_references":

[

{
"method": 
"GET"
,
"endpoint": 
"/assistants/{assistant_id}/subgraphs"
,
"parameters":

[
"assistant_id"
,
"recurse"
]
}
]
}

,

{
"title": 
"Get Assistant Schemas"
,
"description": 
"Get an assistant's schemas by ID."
,
"code_examples":

[
"```hljs curl curl 'https://langchain-ai.github.io/assistants/{assistant_id}/schemas' ```"
]
,
"api_references":

[

{
"method": 
"GET"
,
"endpoint": 
"/assistants/{assistant_id}/schemas"
,
"parameters":

[
"assistant_id"
]
}
]
}

,

{
"title": 
"Get Assistant Versions"
,
"description": 
"Get all versions of an assistant."
,
"code_examples":

[
"```hljs curl curl 'https://langchain-ai.github.io/assistants/{assistant_id}/versions' \ --request POST ```"
]
,
"api_references":

[

{
"method": 
"POST"
,
"endpoint": 
"/assistants/{assistant_id}/versions"
,
"parameters":

[
"assistant_id"
]
}
]
}

,

{
"title": 
"Set Latest Assistant Version"
,
"description": 
"Set the latest version for an assistant."
,
"code_examples":

[
"```hljs curl curl 'https://langchain-ai.github.io/assistants/{assistant_id}/latest?version=' \ --request POST ```"
]
,
"api_references":

[

{
"method": 
"POST"
,
"endpoint": 
"/assistants/{assistant_id}/latest"
,
"parameters":

[
"assistant_id"
,
"version"
]
}
]
}

,

{
"title": 
"LangGraph.js - Quickstart"
,
"description": 
"In this quickstart guide, you'll get up and running with a simple Reason + Act Agent (often called a ReAct Agent) that can search the web using Tavily Search API. The code is fully configurable. You can swap out components, customize the execution flow, extend it with custom code or tooling, and change the Large Language Model (LLM) and provider being used."
,
"code_examples":

[
"mkdir langgraph-agent"
,
"cd langgraph-agent"
,
"npm install @langchain/core @langchain/langgraph @langchain/openai @langchain/community"
,
"process.env.OPENAI_API_KEY = "sk-...";"
,
"process.env.TAVILY_API_KEY = "tvly-...";"
,
"const agentFinalState = await agent.invoke({ messages: [new HumanMessage("what is the current weather in sf")] }, { configurable: { thread_id: "42" } });"
,
"console.log(agentFinalState.messages[agentFinalState.messages.length - 1].content);"
]
,
"api_references":

[

{
"method": 
"POST"
,
"endpoint": 
"/invoke"
,
"parameters":

[
"messages"
,
"configurable"
]
}
,

{
"method": 
"GET"
,
"endpoint": 
"/weather"
,
"parameters":

[
"location"
]
}
]
}

,

{
"title": 
"API Reference"
,
"description": 
"The LangGraph Cloud API reference is available with each deployment at the `/docs` URL path (e.g. `http://localhost:8124/docs`)."
,
"code_examples":

[
"curl --request POST \ --url http://localhost:8124/assistants/search \ --header 'Content-Type: application/json' \ --header 'X-Api-Key: LANGSMITH_API_KEY' \ --data '{\n "metadata": {},\n "limit": 10,\n "offset": 0\n}'"
]
,
"api_references":

[

{
"method": 
"POST"
,
"endpoint": 
"http://localhost:8124/assistants/search"
,
"parameters":

[
"X-Api-Key"
,
"Content-Type"
,
"metadata"
,
"limit"
,
"offset"
]
}
]
}

,

{
"title": 
"Overview"
,
"description": 
"LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows."
,
"code_examples":

[
]
,
"api_references":

[
]
}

,

{
"title": 
"Why use LangGraph?"
,
"description": 
"LangGraph powers production-grade agents, trusted by Linkedin, Uber, Klarna, GitLab, and many more. It provides fine-grained control over both the flow and state of your agent applications."
,
"code_examples":

[
]
,
"api_references":

[
]
}

,

{
"title": 
"LangGraph Platform"
,
"description": 
"LangGraph Platform is infrastructure for deploying LangGraph agents. It is a commercial solution for deploying agentic applications to production, built on the open-source LangGraph framework."
,
"code_examples":

[
]
,
"api_references":

[
]
}

,

{
"title": 
"Installation"
,
"description": 
"Install LangGraph using npm."
,
"code_examples":

[
"npm install @langchain/langgraph @langchain/core"
]
,
"api_references":

[
]
}

,

{
"title": 
"Example"
,
"description": 
"Let's build a tool-calling ReAct-style agent that uses a search tool!"
,
"code_examples":

[
"npm install @langchain/anthropic zod"
,
"export ANTHROPIC_API_KEY=sk-..."
,
"export LANGSMITH_TRACING=true"
,
"export LANGSMITH_API_KEY=lsv2_sk_..."
,
"import { createReactAgent } from "@langchain/langgraph/prebuilt";"
,
"const result = await app.invoke({ messages: [{ role: "user", content: "what is the weather in sf" }] }, { configurable: { thread_id: 42 } });"
,
"console.log(result.messages.at(-1)?.content);"
]
,
"api_references":

[
]
}

,

{
"title": 
"Step-by-step Breakdown"
,
"description": 
"A detailed breakdown of how to implement a tool-calling agent from scratch using LangGraph."
,
"code_examples":

[
]
,
"api_references":

[
]
}

,

{
"title": 
"Documentation"
,
"description": 
"Learn to build with LangGraph through guided examples, accomplish specific tasks, and review important classes and methods."
,
"code_examples":

[
]
,
"api_references":

[

{
"method": 
"GET"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/tutorials/"
,
"parameters":

[
]
}
,

{
"method": 
"GET"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/how-tos/"
,
"parameters":

[
]
}
,

{
"method": 
"GET"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/concepts/high_level/"
,
"parameters":

[
]
}
,

{
"method": 
"GET"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/"
,
"parameters":

[
]
}
,

{
"method": 
"GET"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/concepts/#langgraph-platform"
,
"parameters":

[
]
}
]
}

,

{
"title": 
"Root"
,
"description": 
"Helper function that instantiates a StateGraph state. See Annotation for usage."
,
"code_examples":

[
]
,
"api_references":

[

{
"method": 
"GET"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/functions/langgraph.Annotation.Root.html"
,
"parameters":

[
"sd: S"
]
}
]
}

,

{
"title": 
"IsLastStepManager"
,
"description": 
"The IsLastStepManager class is a part of the langgraph library that manages the state of whether the last step has been reached in a process. It extends the ManagedValue class and provides methods to handle promises and manage the state effectively."
,
"code_examples":

[
]
,
"api_references":

[

{
"method": 
"POST"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.IsLastStepManager.html#constructor"
,
"parameters":

[
"config: RunnableConfig<Record<string, any>>"
,
"_params?: ManagedValueParams"
]
}
,

{
"method": 
"call"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.IsLastStepManager.html#call"
,
"parameters":

[
"step: number"
]
}
,

{
"method": 
"promises"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.IsLastStepManager.html#promises"
,
"parameters":

[
]
}
,

{
"method": 
"initialize"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.IsLastStepManager.html#initialize"
,
"parameters":

[
"_config: RunnableConfig<Record<string, any>>"
,
"_args?: any"
]
}
,

{
"method": 
"addPromise"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.IsLastStepManager.html#addPromise"
,
"parameters":

[
"promise: Promise<unknown>"
]
}
]
}

,

{
"title": 
"createFunctionCallingExecutor"
,
"description": 
"Creates a Function Calling Executor that can manage function calls within a state graph."
,
"code_examples":

[
]
,
"api_references":

[

{
"method": 
"createFunctionCallingExecutor"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/functions/langgraph_prebuilt.createFunctionCallingExecutor.html"
,
"parameters":

[
"model"
,
"tools"
]
}
]
}

,

{
"title": 
"ToolInvocationInterface"
,
"description": 
"Interface for invoking a tool"
,
"code_examples":

[
]
,
"api_references":

[

{
"method": 
""
,
"endpoint": 
""
,
"parameters":

[
"tool"
,
"toolInput"
]
}
]
}

,

{
"title": 
"ToolExecutor"
,
"description": 
"The ToolExecutor class is a deprecated class that is used to execute tools in the langGraph.js framework. It is recommended to use ToolNode instead."
,
"code_examples":

[
]
,
"api_references":

[

{
"method": 
"POST"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolExecutor.html#invoke"
,
"parameters":

[
"input"
,
"options"
]
}
,

{
"method": 
"GET"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolExecutor.html#batch"
,
"parameters":

[
"inputs"
,
"options"
,
"batchOptions"
]
}
,

{
"method": 
"GET"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolExecutor.html#stream"
,
"parameters":

[
"input"
,
"options"
]
}
,

{
"method": 
"GET"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolExecutor.html#streamEvents"
,
"parameters":

[
"input"
,
"options"
,
"streamOptions"
]
}
,

{
"method": 
"GET"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolExecutor.html#streamLog"
,
"parameters":

[
"input"
,
"options"
,
"streamOptions"
]
}
]
}

,

{
"title": 
"Graph"
,
"description": 
"The Graph class is a core component of the langGraph.js library, allowing users to create and manage directed graphs with nodes and edges. It supports various operations such as adding nodes and edges, compiling the graph, and validating its structure."
,
"code_examples":

[
]
,
"api_references":

[

{
"method": 
"constructor"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.Graph.html#constructor"
,
"parameters":

[
"N extends string = typeof END"
,
"RunInput = any"
,
"RunOutput = any"
,
"NodeSpecType extends NodeSpec<RunInput, RunOutput>"
,
"C extends StateDefinition"
]
}
,

{
"method": 
"addConditionalEdges"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.Graph.html#addConditionalEdges"
,
"parameters":

[
"source: BranchOptions<RunInput, N, LangGraphRunnableConfig<StateType<C>>>"
]
}
,

{
"method": 
"addEdge"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.Graph.html#addEdge"
,
"parameters":

[
"startKey: '__start__' | N"
,
"endKey: '__end__' | N"
]
}
,

{
"method": 
"addNode"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.Graph.html#addNode"
,
"parameters":

[
"key: K"
,
"action: RunnableLike<NodeInput, RunOutput>"
,
"options?: AddNodeOptions"
]
}
,

{
"method": 
"compile"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.Graph.html#compile"
,
"parameters":

[
"__namedParameters?: { checkpointer?: false | BaseCheckpointSaver<number>; interruptAfter?: '*' | N[]; interruptBefore?: '*' | N[]; name?: string; }"
]
}
,

{
"method": 
"setEntryPoint"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.Graph.html#setEntryPoint"
,
"parameters":

[
"key: N"
]
}
,

{
"method": 
"setFinishPoint"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.Graph.html#setFinishPoint"
,
"parameters":

[
"key: N"
]
}
,

{
"method": 
"validate"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.Graph.html#validate"
,
"parameters":

[
"interrupt?: string[]"
]
}
,

{
"method": 
"warnIfCompiled"
,
"endpoint": 
"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.Graph.html#warnIfCompiled"
,
"parameters":

[
"message: string"
]
}
]
}

,

{
"title": 
"How to add semantic search to your agent's memory"
,
"description": 
"This guide shows how to enable semantic search in your agent's memory store. This lets search for items in the store by semantic similarity."
,
"code_examples":

[
"npm install @langchain/langgraph @langchain/openai @langchain/core uuid zod"
,
"export OPENAI_API_KEY=your-api-key"
,
"export LANGCHAIN_TRACING_V2="true""
,
"const embeddings = new OpenAIEmbeddings({ model: "text-embedding-3-small" });"
,
"const store = new InMemoryStore({ index: { embeddings, dims: 1536 } });"
,
"await store.put(["user_123", "memories"], "1", {"text": "I love pizza"})"
,
"const memories = await store.search(["user_123", "memories"], { query: "I like food?", limit: 5 });"
,
"const addMemories = async (state, config) => { const store = config.store; const items = await store.search(["user_123", "memories"], { query: state.messages[state.messages.length - 1].content, limit: 2 }); return [{ role: "system", content: `You are a helpful assistant.\n${items.map(item => item.value.text).join("\n")}` }, ...state.messages]; };"
,
"const upsertMemoryTool = tool(async (input, config) => { const store = config.store; const memoryId = getContextVariable("memoryId") || uuidv4(); await store.put(["user_123", "memories"], memoryId, { text: input.content }); return `Stored memory ${memoryId}`; }, { name: "upsert_memory", schema: z.object({ content: z.string() }), description: "Upsert a memory in the database." });"
,
"const agent = createReactAgent({ llm: new ChatOpenAI({ model: "gpt-4o-mini" }), tools: [upsertMemoryTool], stateModifier: addMemories, store: store });"
,
"const stream = await agent.stream({ messages: [{ role: "user", content: "I'm hungry" }], streamMode: "messages" });"
]
,
"api_references":

[

{
"method": 
"POST"
,
"endpoint": 
"/store/put"
,
"parameters":

[
"user_id"
,
"memory_id"
,
"memory_content"
]
}
,

{
"method": 
"GET"
,
"endpoint": 
"/store/search"
,
"parameters":

[
"user_id"
,
"query"
,
"limit"
]
}
]
}

,

{
"title": 
"How to add human-in-the-loop processes to the prebuilt ReAct agent"
,
"description": 
"This tutorial will show how to add human-in-the-loop processes to the prebuilt ReAct agent. Please see this tutorial for how to get started with the prebuilt ReAct agent."
,
"code_examples":

[
"yarn add @langchain/langgraph @langchain/openai @langchain/core"
,
"process.env.LANGCHAIN_CALLBACKS_BACKGROUND = "true";"
,
"const model = new ChatOpenAI({ model: "gpt-4o" });"
,
"const getWeather = tool((input) => { if (['sf', 'san francisco'].includes(input.location.toLowerCase())) { return 'It\'s always sunny in sf'; } else if (['nyc', 'new york city'].includes(input.location.toLowerCase())) { return 'It might be cloudy in nyc'; } else { throw new Error("Unknown Location"); } }, { name: 'get_weather', description: 'Call to get the current weather in a given location.', schema: z.object({ location: z.string().describe("Location to get the weather for."), }) });"
,
"const memory = new MemorySaver();"
,
"const agent = createReactAgent({ llm: model, tools: [getWeather], interruptBefore: ["tools"], checkpointSaver: memory });"
,
"let inputs = { messages: [{ role: "user", content: "what is the weather in SF california?" }] };"
,
"let stream = await agent.stream(inputs, { ...config, streamMode: "values", });"
,
"const state = await agent.getState(config);"
,
"let lastMessage = currentState.values.messages[currentState.values.messages.length - 1];"
,
"lastMessage.tool_calls[0].args = { location: "San Francisco" };"
,
"await agent.updateState(config, { messages: lastMessage });"
,
"stream = await agent.stream(null, { ...config, streamMode: "values", });"
]
,
"api_references":

[

{
"method": 
"POST"
,
"endpoint": 
"/createReactAgent"
,
"parameters":

[
"llm"
,
"tools"
,
"interruptBefore"
,
"checkpointSaver"
]
}
,

{
"method": 
"GET"
,
"endpoint": 
"/getState"
,
"parameters":

[
"config"
]
}
,

{
"method": 
"POST"
,
"endpoint": 
"/updateState"
,
"parameters":

[
"config"
,
"messages"
]
}
,

{
"method": 
"POST"
,
"endpoint": 
"/stream"
,
"parameters":

[
"inputs"
,
"config"
]
}
]
}

,

{
"title": 
"How to update graph state from tools"
,
"description": 
"This guide shows how to update graph state from inside a tool, using a customer support application as an example. It explains how to return a Command object from the tool to update the graph state."
,
"code_examples":

[
"import { tool } from "@langchain/core/tools"; const lookupUserInfo = tool(async (input, config) => { const userInfo = getUserInfo(config); return new Command({ // update state keys update: { user_info: userInfo, messages: [ new ToolMessage({ content: "Successfully looked up user information", tool_call_id: config.toolCall.id, }), ], }, }); }, { name: "lookup_user_info", description: "Use this to look up user information to better assist them with their questions.", schema: z.object(...) });"
,
"const USER_ID_TO_USER_INFO = { abc123: { user_id: "abc123", name: "Bob Dylan", location: "New York, NY", }, zyx987: { user_id: "zyx987", name: "Taylor Swift", location: "Beverly Hills, CA", }, };"
,
"const stateModifier = (state: typeof StateAnnotation.State) => { const userInfo = state.userInfo; if (userInfo == null) { return state.messages; } const systemMessage = `User name is ${userInfo.name}. User lives in ${userInfo.location}`; return [{ role: "system", content: systemMessage, }, ...state.messages]; };"
,
"const agent = createReactAgent({ llm: model, tools: [lookupUserInfo], stateSchema: StateAnnotation, stateModifier: stateModifier, })"
]
,
"api_references":

[

{
"method": 
"POST"
,
"endpoint": 
"/api/tools/lookup_user_info"
,
"parameters":

[
"input"
,
"config"
]
}
,

{
"method": 
"GET"
,
"endpoint": 
"/api/user_info"
,
"parameters":

[
"user_id"
]
}
,

{
"method": 
"POST"
,
"endpoint": 
"/api/agent/create"
,
"parameters":

[
"llm"
,
"tools"
,
"stateSchema"
,
"stateModifier"
]
}
]
}

,

{
"title": 
"Self-RAG"
,
"description": 
"Self-reflection can enhance RAG, enabling correction of poor quality retrieval or generations. This tutorial shows how to implement ideas from the Self RAG paper using LangGraph."
,
"code_examples":

[
"import "dotenv/config";"
,
"npm install cheerio zod langchain @langchain/community @langchain/openai @langchain/core @langchain/textsplitters"
,
"const urls = ["https://lilianweng.github.io/posts/2023-06-23-agent/", "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/", "https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/"];"
,
"const docs = await Promise.all(urls.map((url) => new CheerioWebBaseLoader(url).load()));"
,
"const vectorStore = await MemoryVectorStore.fromDocuments(docSplits, new OpenAIEmbeddings({ model: "text-embedding-3-large" }));"
,
"const workflow = new StateGraph(GraphState) .addNode("retrieve", retrieve) .addNode("gradeDocuments", gradeDocuments) .addNode("generate", generate);"
,
"const inputs = { question: "Explain how the different types of agent memory work." };"
]
,
"api_references":

[

{
"method": 
"GET"
,
"endpoint": 
"/self-rag"
,
"parameters":

[
"question"
]
}
,

{
"method": 
"POST"
,
"endpoint": 
"/retrieve"
,
"parameters":

[
"state"
]
}
,

{
"method": 
"POST"
,
"endpoint": 
"/generate"
,
"parameters":

[
"state"
]
}
,

{
"method": 
"POST"
,
"endpoint": 
"/gradeDocuments"
,
"parameters":

[
"state"
]
}
,

{
"method": 
"POST"
,
"endpoint": 
"/transformQuery"
,
"parameters":

[
"state"
]
}
,

{
"method": 
"POST"
,
"endpoint": 
"/generateGenerationVDocumentsGrade"
,
"parameters":

[
"state"
]
}
,

{
"method": 
"POST"
,
"endpoint": 
"/generateGenerationVQuestionGrade"
,
"parameters":

[
"state"
]
}
]
}

,

{
"title": 
"Corrective RAG (CRAG)"
,
"description": 
"Self-reflection can enhance RAG, enabling correction of poor quality retrieval or generations. This tutorial shows how to implement ideas from the Corrective RAG (CRAG) paper using LangGraph."
,
"code_examples":

[
"import "dotenv/config";"
,
"npm install cheerio zod langchain @langchain/community @langchain/openai @langchain/core @langchain/textsplitters @langchain/langgraph"
,
"const urls = ["https://lilianweng.github.io/posts/2023-06-23-agent/","https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/","https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/"];"
,
"const docs = await Promise.all(urls.map((url) => new CheerioWebBaseLoader(url).load()));"
,
"const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 250, chunkOverlap: 0 });"
,
"const vectorStore = await MemoryVectorStore.fromDocuments(docSplits, new OpenAIEmbeddings());"
,
"const model = new ChatOpenAI({ model: "gpt-4o", temperature: 0 });"
,
"const workflow = new StateGraph(GraphState).addNode("retrieve", retrieve).addNode("gradeDocuments", gradeDocuments).addNode("generate", generate).addNode("transformQuery", transformQuery).addNode("webSearch", webSearch);"
,
"const inputs = { question: "Explain how the different types of agent memory work." };"
]
,
"api_references":

[

{
"method": 
"GET"
,
"endpoint": 
"https://api.tavily.com/search"
,
"parameters":

[
"input"
]
}
,

{
"method": 
"POST"
,
"endpoint": 
"https://api.openai.com/v1/chat/completions"
,
"parameters":

[
"model"
,
"messages"
,
"temperature"
]
}
]
}

,

{
"title": 
"getStore"
,
"description": 
"A helper utility function that returns the BaseStore that was set when the graph was initialized"
,
"code_examples":

[
]
,
"api_references":

[

{
"method": 
"GET"
,
"endpoint": 
"langgraph.getStore"
,
"parameters":

[
]
}
]
}

,

{
"title": 
"BaseChannel"
,
"description": 
"The BaseChannel class is an abstract class that serves as a foundation for creating various types of channels in the langGraph.js framework. It defines the structure and methods that all channel types must implement, including methods for updating and retrieving values, as well as managing checkpoints."
,
"code_examples":

[
]
,
"api_references":

[

{
"method": 
"POST"
,
"endpoint": 
"BaseChannel.constructor"
,
"parameters":

[
"ValueType"
,
"UpdateType"
,
"CheckpointType"
]
}
,

{
"method": 
"GET"
,
"endpoint": 
"BaseChannel.get"
,
"parameters":

[
]
}
,

{
"method": 
"POST"
,
"endpoint": 
"BaseChannel.update"
,
"parameters":

[
"values: UpdateType[]"
]
}
,

{
"method": 
"GET"
,
"endpoint": 
"BaseChannel.checkpoint"
,
"parameters":

[
]
}
,

{
"method": 
"POST"
,
"endpoint": 
"BaseChannel.fromCheckpoint"
,
"parameters":

[
"checkpoint?: CheckpointType"
]
}
,

{
"method": 
"POST"
,
"endpoint": 
"BaseChannel.consume"
,
"parameters":

[
]
}
]
}

,

{
"title": 
"How to configure multiple streaming modes at the same time"
,
"description": 
"This guide covers how to configure multiple streaming modes at the same time."
,
"code_examples":

[
"npm install @langchain/langgraph @langchain/openai @langchain/core"
,
"export OPENAI_API_KEY=your-api-key"
,
"export LANGCHAIN_TRACING_V2="true""
,
"export LANGCHAIN_CALLBACKS_BACKGROUND="true""
,
"export LANGCHAIN_API_KEY=your-api-key"
,
"import { ChatOpenAI } from "@langchain/openai";"
,
"import { tool } from '@langchain/core/tools';"
,
"import { z } from 'zod';"
,
"import { createReactAgent } from "@langchain/langgraph/prebuilt";"
,
"const model = new ChatOpenAI({ model: "gpt-4o", });"
,
"const getWeather = tool((input) => { if (["sf", "san francisco", "san francisco, ca"].includes(input.location.toLowerCase())) { return "It's 60 degrees and foggy."; } else { return "It's 90 degrees and sunny."; } }, { name: "get_weather", description: "Call to get the current weather.", schema: z.object({ location: z.string().describe("Location to get the weather for."), }) })"
,
"const graph = createReactAgent({ llm: model, tools: [getWeather] });"
,
"let inputs = { messages: [{ role: "user", content: "what's the weather in sf?" }] };"
,
"let stream = await graph.stream(inputs, { streamMode: ["updates", "debug"], });"
,
"for await (const chunk of stream) { console.log(`Receiving new event of type: ${chunk[0]}`); console.log(chunk[1]); console.log("\n====\n"); }"
]
,
"api_references":

[

{
"method": 
"POST"
,
"endpoint": 
"/stream"
,
"parameters":

[
"messages"
,
"streamMode"
]
}
]
}

,

{
"title": 
"How to stream state updates of your graph"
,
"description": 
"LangGraph supports multiple streaming modes. The main ones are: 'values' which streams back the full state of the graph after each node is called, and 'updates' which streams back updates to the state of the graph after each node is called. This guide covers streamMode='updates'."
,
"code_examples":

[
"// process.env.OPENAI_API_KEY = "sk-...";"
,
"import { Annotation } from "@langchain/langgraph";"
,
"import { BaseMessage } from "@langchain/core/messages";"
,
"const StateAnnotation = Annotation.Root({ messages: Annotation<BaseMessage[]>({ reducer: (x, y) => x.concat(y), }), });"
,
"import { tool } from "@langchain/core/tools";"
,
"import { z } from "zod";"
,
"const searchTool = tool(async ({ query: _query }: { query: string }) => { return "Cold, with a low of 3â„ƒ"; }, { name: "search", description: "Use to surf the web, fetch current information, check the weather, and retrieve other information.", schema: z.object({ query: z.string().describe("The query to use in your search."), }), });"
,
"await searchTool.invoke({ query: "What's the weather like?" });"
,
"const tools = [searchTool];"
,
"import { ToolNode } from "@langchain/langgraph/prebuilt";"
,
"const toolNode = new ToolNode(tools);"
,
"import { ChatOpenAI } from "@langchain/openai";"
,
"const model = new ChatOpenAI({ model: "gpt-4o" });"
,
"const boundModel = model.bindTools(tools);"
,
"import { END, START, StateGraph } from "@langchain/langgraph";"
,
"import { AIMessage } from "@langchain/core/messages";"
,
"const routeMessage = (state: typeof StateAnnotation.State) => { const { messages } = state; const lastMessage = messages[messages.length - 1] as AIMessage; if (!lastMessage?.tool_calls?.length) { return END; } return "tools"; };"
,
"const callModel = async (state: typeof StateAnnotation.State,) => { const { messages } = state; const responseMessage = await boundModel.invoke(messages); return { messages: [responseMessage] }; };"
,
"const workflow = new StateGraph(StateAnnotation) .addNode("agent", callModel) .addNode("tools", toolNode) .addEdge(START, "agent") .addConditionalEdges("agent", routeMessage) .addEdge("tools", "agent");"
,
"const graph = workflow.compile();"
,
"let inputs = { messages: [{ role: "user", content: "what's the weather in sf" }] };"
,
"for await ( const chunk of await graph.stream(inputs, { streamMode: "updates", }) ) { for (const [node, values] of Object.entries(chunk)) { console.log(`Receiving update from node: ${node}`); console.log(values); console.log("\n====\n"); } }"
]
,
"api_references":

[

{
"method": 
"POST"
,
"endpoint": 
"/stream"
,
"parameters":

[
"messages"
,
"streamMode"
]
}
]
}

]
}
]
